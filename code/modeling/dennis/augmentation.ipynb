{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quadratic Weighted Kappa function\n",
    "def Cmatrix(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the confusion matrix between rater's ratings\n",
    "    \"\"\"\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(rater_a + rater_b)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(rater_a + rater_b)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    conf_mat = [[0 for i in range(num_ratings)]\n",
    "                for j in range(num_ratings)]\n",
    "    for a, b in zip(rater_a, rater_b):\n",
    "        conf_mat[a - min_rating][b - min_rating] += 1\n",
    "    return conf_mat\n",
    "\n",
    "\n",
    "def histogram(ratings, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the counts of each type of rating that a rater made\n",
    "    \"\"\"\n",
    "    if min_rating is None:\n",
    "        min_rating = min(ratings)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(ratings)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    hist_ratings = [0 for x in range(num_ratings)]\n",
    "    for r in ratings:\n",
    "        hist_ratings[r - min_rating] += 1\n",
    "    return hist_ratings\n",
    "\n",
    "def quadratic_weighted_kappa(y, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the quadratic weighted kappa\n",
    "    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n",
    "    value, which is a measure of inter-rater agreement between two raters\n",
    "    that provide discrete numeric ratings.  Potential values range from -1\n",
    "    (representing complete disagreement) to 1 (representing complete\n",
    "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
    "    chance.\n",
    "    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n",
    "    each correspond to a list of integer ratings.  These lists must have the\n",
    "    same length.\n",
    "    The ratings should be integers, and it is assumed that they contain\n",
    "    the complete range of possible ratings.\n",
    "    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
    "    is the minimum possible rating, and max_rating is the maximum possible\n",
    "    rating\n",
    "    \"\"\"\n",
    "    rater_a = y\n",
    "    rater_b = y_pred\n",
    "    min_rating=None\n",
    "    max_rating=None\n",
    "    rater_a = np.array(rater_a, dtype=int)\n",
    "    rater_b = np.array(rater_b, dtype=int)\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(min(rater_a), min(rater_b))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(max(rater_a), max(rater_b))\n",
    "    conf_mat = Cmatrix(rater_a, rater_b,\n",
    "                                min_rating, max_rating)\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(rater_a))\n",
    "\n",
    "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    "\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
    "                              / num_scored_items)\n",
    "            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n",
    "            numerator += d * conf_mat[i][j] / num_scored_items\n",
    "            denominator += d * expected_count / num_scored_items\n",
    "\n",
    "    return (1.0 - numerator / denominator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "images = np.load('blindness_images.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3662, 128, 128, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = images\n",
    "y = train['diagnosis']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = 42)\n",
    "\n",
    "y_train = utils.to_categorical(y_train, 5)\n",
    "y_test = utils.to_categorical(y_test, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried running other models before in a different notebook, however they left me wanting for more approaches that could score better. In my search was Image Augmentation, where the images are manipulated to help the model train on data that wasn't all the same. Doing so should in theory assist the model in identifying underlying patterns. What follows below is my attempt at seeing what stuck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Conv Layer Model without Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 25s 2s/step - loss: 1.3081 - accuracy: 0.4403 - val_loss: 1.1361 - val_accuracy: 0.6343\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.9782 - accuracy: 0.6672 - val_loss: 0.8644 - val_accuracy: 0.6943\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.8309 - accuracy: 0.7028 - val_loss: 0.8277 - val_accuracy: 0.6900\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.7835 - accuracy: 0.7145 - val_loss: 0.8230 - val_accuracy: 0.7074\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.7573 - accuracy: 0.7229 - val_loss: 0.8074 - val_accuracy: 0.7009\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.7256 - accuracy: 0.7363 - val_loss: 0.7947 - val_accuracy: 0.7216\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.6961 - accuracy: 0.7418 - val_loss: 0.7641 - val_accuracy: 0.7249\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.6818 - accuracy: 0.7516 - val_loss: 0.7637 - val_accuracy: 0.7238\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.6558 - accuracy: 0.7600 - val_loss: 0.7592 - val_accuracy: 0.7293\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.6488 - accuracy: 0.7633 - val_loss: 0.7527 - val_accuracy: 0.7303\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 25s 2s/step - loss: 0.6404 - accuracy: 0.7680 - val_loss: 0.7455 - val_accuracy: 0.7325\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.6247 - accuracy: 0.7669 - val_loss: 0.7462 - val_accuracy: 0.7413\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 24s 2s/step - loss: 0.5924 - accuracy: 0.7779 - val_loss: 0.7383 - val_accuracy: 0.7391\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.5711 - accuracy: 0.7819 - val_loss: 0.8369 - val_accuracy: 0.7303\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.5657 - accuracy: 0.7921 - val_loss: 0.7912 - val_accuracy: 0.7380\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.5339 - accuracy: 0.8037 - val_loss: 0.7771 - val_accuracy: 0.7303\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.4992 - accuracy: 0.8132 - val_loss: 0.7974 - val_accuracy: 0.7445\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.5305 - accuracy: 0.7953 - val_loss: 0.8511 - val_accuracy: 0.7282\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.5341 - accuracy: 0.8117 - val_loss: 0.8467 - val_accuracy: 0.7271\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.4693 - accuracy: 0.8281 - val_loss: 0.8181 - val_accuracy: 0.7282\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.4220 - accuracy: 0.8405 - val_loss: 0.8666 - val_accuracy: 0.7456\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.3821 - accuracy: 0.8583 - val_loss: 0.9444 - val_accuracy: 0.7194\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.3912 - accuracy: 0.8529 - val_loss: 0.8448 - val_accuracy: 0.7391\n",
      "Epoch 00023: early stopping\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "# https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Course%202%20-%20Part%204%20-%20Lesson%202%20-%20Notebook%20(Cats%20v%20Dogs%20Augmentation).ipynb\n",
    "model_test = Sequential()\n",
    "\n",
    "model_test.add(Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)))\n",
    "model_test.add(MaxPooling2D(2, 2))\n",
    "model_test.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model_test.add(MaxPooling2D(2,2))\n",
    "model_test.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model_test.add(MaxPooling2D(2,2))\n",
    "model_test.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model_test.add(MaxPooling2D(2,2))\n",
    "\n",
    "model_test.add(Flatten())\n",
    "\n",
    "model_test.add(Dense(512, activation='relu'))\n",
    "model_test.add(Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "model_test.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "history_test = model_test.fit(X_train, y_train, validation_data = (X_test, y_test),\n",
    "                 batch_size = 256,\n",
    "                 epochs = 100,\n",
    "                 verbose = 1,\n",
    "                  callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7367323696136592"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = model_test.predict(X_test)\n",
    "quadratic_weighted_kappa(np.argmax(y_test,axis=1), np.argmax(pred_test,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tested multiple convolutional layers and was surprised that even without augmentation it performed well. If there was any augmentation that could be done to improve the kappa score, I would happy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Conv Layer with Augmentation Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 36s 3s/step - loss: 1.3420 - accuracy: 0.4388 - val_loss: 1.2763 - val_accuracy: 0.4924\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 34s 3s/step - loss: 1.2506 - accuracy: 0.4931 - val_loss: 1.1737 - val_accuracy: 0.4913\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 34s 3s/step - loss: 1.2061 - accuracy: 0.4945 - val_loss: 1.1328 - val_accuracy: 0.5611\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 33s 3s/step - loss: 1.1503 - accuracy: 0.5393 - val_loss: 1.0874 - val_accuracy: 0.6157\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 32s 3s/step - loss: 1.0584 - accuracy: 0.5852 - val_loss: 0.9571 - val_accuracy: 0.6714\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 33s 3s/step - loss: 0.9874 - accuracy: 0.6391 - val_loss: 0.9108 - val_accuracy: 0.6747\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 34s 3s/step - loss: 0.9331 - accuracy: 0.6595 - val_loss: 0.9023 - val_accuracy: 0.6681\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 34s 3s/step - loss: 0.8997 - accuracy: 0.6675 - val_loss: 0.8917 - val_accuracy: 0.6856\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.8809 - accuracy: 0.6719 - val_loss: 0.8696 - val_accuracy: 0.6878\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.8856 - accuracy: 0.6832 - val_loss: 0.9172 - val_accuracy: 0.6561\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.8825 - accuracy: 0.6755 - val_loss: 0.8687 - val_accuracy: 0.6943\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.8366 - accuracy: 0.6948 - val_loss: 0.8291 - val_accuracy: 0.6943\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.8274 - accuracy: 0.7032 - val_loss: 0.8302 - val_accuracy: 0.6965\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.8102 - accuracy: 0.7087 - val_loss: 0.8287 - val_accuracy: 0.6998\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7910 - accuracy: 0.7156 - val_loss: 0.8526 - val_accuracy: 0.6932\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.8109 - accuracy: 0.7090 - val_loss: 0.8177 - val_accuracy: 0.6867\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.8120 - accuracy: 0.7025 - val_loss: 0.8606 - val_accuracy: 0.7063\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.8095 - accuracy: 0.7028 - val_loss: 0.8446 - val_accuracy: 0.7020\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7711 - accuracy: 0.7178 - val_loss: 0.8196 - val_accuracy: 0.6965\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7614 - accuracy: 0.7174 - val_loss: 0.8304 - val_accuracy: 0.7118\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.7731 - accuracy: 0.7232 - val_loss: 0.8510 - val_accuracy: 0.7052\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.7456 - accuracy: 0.7323 - val_loss: 0.8313 - val_accuracy: 0.7063\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7363 - accuracy: 0.7251 - val_loss: 0.8079 - val_accuracy: 0.7172\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.7380 - accuracy: 0.7334 - val_loss: 0.8170 - val_accuracy: 0.7063\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7458 - accuracy: 0.7280 - val_loss: 0.8076 - val_accuracy: 0.7162\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.7382 - accuracy: 0.7320 - val_loss: 0.8254 - val_accuracy: 0.7074\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.7502 - accuracy: 0.7298 - val_loss: 0.8035 - val_accuracy: 0.7107\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.7512 - accuracy: 0.7218 - val_loss: 0.8379 - val_accuracy: 0.7052\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.7228 - accuracy: 0.7345 - val_loss: 0.8069 - val_accuracy: 0.7118\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.7197 - accuracy: 0.7356 - val_loss: 0.8278 - val_accuracy: 0.7249\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.7043 - accuracy: 0.7436 - val_loss: 0.7766 - val_accuracy: 0.7205\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.6900 - accuracy: 0.7546 - val_loss: 0.7783 - val_accuracy: 0.7293\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.7000 - accuracy: 0.7389 - val_loss: 0.7796 - val_accuracy: 0.7260\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.7030 - accuracy: 0.7422 - val_loss: 0.7951 - val_accuracy: 0.7260\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6950 - accuracy: 0.7447 - val_loss: 0.7879 - val_accuracy: 0.7303\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.6862 - accuracy: 0.7524 - val_loss: 0.7779 - val_accuracy: 0.7271\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.6953 - accuracy: 0.7396 - val_loss: 0.7800 - val_accuracy: 0.7194\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6898 - accuracy: 0.7429 - val_loss: 0.7763 - val_accuracy: 0.7282\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6762 - accuracy: 0.7487 - val_loss: 0.7674 - val_accuracy: 0.7325\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6737 - accuracy: 0.7520 - val_loss: 0.7817 - val_accuracy: 0.7118\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.6788 - accuracy: 0.7513 - val_loss: 0.8174 - val_accuracy: 0.7151\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6763 - accuracy: 0.7542 - val_loss: 0.7772 - val_accuracy: 0.7325\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.6718 - accuracy: 0.7407 - val_loss: 0.7877 - val_accuracy: 0.7227\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6640 - accuracy: 0.7538 - val_loss: 0.8042 - val_accuracy: 0.7151\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6553 - accuracy: 0.7524 - val_loss: 0.7654 - val_accuracy: 0.7336\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6602 - accuracy: 0.7578 - val_loss: 0.7582 - val_accuracy: 0.7293\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6543 - accuracy: 0.7527 - val_loss: 0.7836 - val_accuracy: 0.7303\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.6394 - accuracy: 0.7575 - val_loss: 0.7956 - val_accuracy: 0.7271\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6353 - accuracy: 0.7571 - val_loss: 0.7710 - val_accuracy: 0.7238\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6301 - accuracy: 0.7666 - val_loss: 0.7870 - val_accuracy: 0.7129\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6211 - accuracy: 0.7724 - val_loss: 0.7760 - val_accuracy: 0.7238\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6296 - accuracy: 0.7637 - val_loss: 0.7918 - val_accuracy: 0.7325\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.6336 - accuracy: 0.7717 - val_loss: 0.8166 - val_accuracy: 0.7227\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6248 - accuracy: 0.7680 - val_loss: 0.7910 - val_accuracy: 0.7293\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6262 - accuracy: 0.7618 - val_loss: 0.8033 - val_accuracy: 0.7205\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.6374 - accuracy: 0.7662 - val_loss: 0.7826 - val_accuracy: 0.7227\n",
      "Epoch 00056: early stopping\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "# https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Course%202%20-%20Part%204%20-%20Lesson%202%20-%20Notebook%20(Cats%20v%20Dogs%20Augmentation).ipynb\n",
    "data_augmentation2 = Sequential(\n",
    "  [\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\", input_shape=(128,128,3)),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.1, 0.3),\n",
    "    layers.experimental.preprocessing.RandomContrast(0.2),\n",
    "  ]\n",
    ")\n",
    "\n",
    "\n",
    "model_test_aug = Sequential()\n",
    "\n",
    "model_test_aug.add(data_augmentation2)\n",
    "\n",
    "model_test_aug.add(Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)))\n",
    "model_test_aug.add(MaxPooling2D(2, 2))\n",
    "model_test_aug.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model_test_aug.add(MaxPooling2D(2,2))\n",
    "model_test_aug.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model_test_aug.add(MaxPooling2D(2,2))\n",
    "model_test_aug.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model_test_aug.add(MaxPooling2D(2,2))\n",
    "\n",
    "model_test_aug.add(Flatten())\n",
    "\n",
    "model_test_aug.add(Dense(512, activation='relu'))\n",
    "model_test_aug.add(Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "model_test_aug.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "history_test_aug = model_test_aug.fit(X_train, y_train, validation_data = (X_test, y_test),\n",
    "                 batch_size = 256,\n",
    "                 epochs = 100,\n",
    "                 verbose = 1,\n",
    "                  callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6909811825012597"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_aug = model_test_aug.predict(X_test)\n",
    "quadratic_weighted_kappa(np.argmax(y_test,axis=1), np.argmax(pred_aug,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model with augmentation did not score as well as I thought it would. It needed further tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Conv Layer without Contrast and 0.1 Rotation and Zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 1.3304 - accuracy: 0.4399 - val_loss: 1.2023 - val_accuracy: 0.4924\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 1.1892 - accuracy: 0.5018 - val_loss: 1.0411 - val_accuracy: 0.6572\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 1.0244 - accuracy: 0.6318 - val_loss: 0.8745 - val_accuracy: 0.6943\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.9184 - accuracy: 0.6817 - val_loss: 0.8808 - val_accuracy: 0.6965\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.8522 - accuracy: 0.7007 - val_loss: 0.8423 - val_accuracy: 0.7020\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.8086 - accuracy: 0.7134 - val_loss: 0.8227 - val_accuracy: 0.7096\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7838 - accuracy: 0.7189 - val_loss: 0.8225 - val_accuracy: 0.7096\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.7656 - accuracy: 0.7178 - val_loss: 0.8269 - val_accuracy: 0.7118\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.7319 - accuracy: 0.7331 - val_loss: 0.8307 - val_accuracy: 0.7129\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.7438 - accuracy: 0.7302 - val_loss: 0.7685 - val_accuracy: 0.7227\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.7191 - accuracy: 0.7433 - val_loss: 0.8282 - val_accuracy: 0.7162\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7471 - accuracy: 0.7276 - val_loss: 0.8082 - val_accuracy: 0.7271\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7474 - accuracy: 0.7320 - val_loss: 0.7790 - val_accuracy: 0.7238\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.7233 - accuracy: 0.7393 - val_loss: 0.7994 - val_accuracy: 0.7314\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.7242 - accuracy: 0.7276 - val_loss: 0.7934 - val_accuracy: 0.7282\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.7154 - accuracy: 0.7331 - val_loss: 0.7788 - val_accuracy: 0.7314\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6937 - accuracy: 0.7454 - val_loss: 0.7816 - val_accuracy: 0.7162\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6965 - accuracy: 0.7400 - val_loss: 0.7842 - val_accuracy: 0.7336\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.6780 - accuracy: 0.7505 - val_loss: 0.7541 - val_accuracy: 0.7325\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.6825 - accuracy: 0.7451 - val_loss: 0.7440 - val_accuracy: 0.7303\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6662 - accuracy: 0.7578 - val_loss: 0.7731 - val_accuracy: 0.7336\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.6585 - accuracy: 0.7578 - val_loss: 0.7781 - val_accuracy: 0.7424\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6692 - accuracy: 0.7538 - val_loss: 0.7915 - val_accuracy: 0.7336\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.6637 - accuracy: 0.7476 - val_loss: 0.7971 - val_accuracy: 0.7413\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6495 - accuracy: 0.7567 - val_loss: 0.7454 - val_accuracy: 0.7434\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6471 - accuracy: 0.7546 - val_loss: 0.7675 - val_accuracy: 0.7358\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.6538 - accuracy: 0.7564 - val_loss: 0.7629 - val_accuracy: 0.7467\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.6472 - accuracy: 0.7553 - val_loss: 0.7915 - val_accuracy: 0.7227\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.6258 - accuracy: 0.7655 - val_loss: 0.7586 - val_accuracy: 0.7293\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.6233 - accuracy: 0.7666 - val_loss: 0.7812 - val_accuracy: 0.7402\n",
      "Epoch 00030: early stopping\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "# https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Course%202%20-%20Part%204%20-%20Lesson%202%20-%20Notebook%20(Cats%20v%20Dogs%20Augmentation).ipynb\n",
    "data_augmentation2 = Sequential(\n",
    "  [\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(128,128,3)),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.1)\n",
    "  ]\n",
    ")\n",
    "\n",
    "\n",
    "model_test_aug2 = Sequential()\n",
    "\n",
    "model_test_aug2.add(data_augmentation2)\n",
    "\n",
    "model_test_aug2.add(Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)))\n",
    "model_test_aug2.add(MaxPooling2D(2, 2))\n",
    "model_test_aug2.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model_test_aug2.add(MaxPooling2D(2,2))\n",
    "model_test_aug2.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model_test_aug2.add(MaxPooling2D(2,2))\n",
    "model_test_aug2.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model_test_aug2.add(MaxPooling2D(2,2))\n",
    "\n",
    "model_test_aug2.add(Flatten())\n",
    "\n",
    "model_test_aug2.add(Dense(512, activation='relu'))\n",
    "model_test_aug2.add(Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "model_test_aug2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "history_test_aug2 = model_test_aug2.fit(X_train, y_train, validation_data = (X_test, y_test),\n",
    "                 batch_size = 256,\n",
    "                 epochs = 100,\n",
    "                 verbose = 1,\n",
    "                  callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7334413962799997"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_aug2 = model_test_aug2.predict(X_test)\n",
    "quadratic_weighted_kappa(np.argmax(y_test,axis=1), np.argmax(pred_aug2,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite good! Further tuning was required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same Model as above with 0.2 Rotation (Best Augmented Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 1.3429 - accuracy: 0.4348 - val_loss: 1.2497 - val_accuracy: 0.4924\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 1.2228 - accuracy: 0.4931 - val_loss: 1.1618 - val_accuracy: 0.4924\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 1.1801 - accuracy: 0.4967 - val_loss: 1.1257 - val_accuracy: 0.5142\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 1.1233 - accuracy: 0.5466 - val_loss: 1.0756 - val_accuracy: 0.6234\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 1.0544 - accuracy: 0.5929 - val_loss: 0.9412 - val_accuracy: 0.6812\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.9621 - accuracy: 0.6424 - val_loss: 0.9325 - val_accuracy: 0.6550\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.8846 - accuracy: 0.6668 - val_loss: 0.9123 - val_accuracy: 0.6845\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.8240 - accuracy: 0.6959 - val_loss: 0.9377 - val_accuracy: 0.6823\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.8229 - accuracy: 0.6948 - val_loss: 0.9103 - val_accuracy: 0.6943\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.8134 - accuracy: 0.6988 - val_loss: 0.8316 - val_accuracy: 0.7009\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7812 - accuracy: 0.7170 - val_loss: 0.8245 - val_accuracy: 0.6900\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7733 - accuracy: 0.7196 - val_loss: 0.8110 - val_accuracy: 0.7107\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.7686 - accuracy: 0.7196 - val_loss: 0.8027 - val_accuracy: 0.7118\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7699 - accuracy: 0.7200 - val_loss: 0.8368 - val_accuracy: 0.7052\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7389 - accuracy: 0.7287 - val_loss: 0.7747 - val_accuracy: 0.7238\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7469 - accuracy: 0.7280 - val_loss: 0.8093 - val_accuracy: 0.7052\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.7286 - accuracy: 0.7342 - val_loss: 0.8002 - val_accuracy: 0.7194\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7258 - accuracy: 0.7316 - val_loss: 0.8303 - val_accuracy: 0.7140\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7266 - accuracy: 0.7283 - val_loss: 0.7628 - val_accuracy: 0.7303\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.7180 - accuracy: 0.7389 - val_loss: 0.7921 - val_accuracy: 0.7129\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7082 - accuracy: 0.7414 - val_loss: 0.7860 - val_accuracy: 0.7282\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7033 - accuracy: 0.7418 - val_loss: 0.7734 - val_accuracy: 0.7325\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6994 - accuracy: 0.7476 - val_loss: 0.7674 - val_accuracy: 0.7303\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6861 - accuracy: 0.7502 - val_loss: 0.7593 - val_accuracy: 0.7238\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.6905 - accuracy: 0.7473 - val_loss: 0.7476 - val_accuracy: 0.7358\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.6970 - accuracy: 0.7454 - val_loss: 0.7613 - val_accuracy: 0.7249\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6874 - accuracy: 0.7447 - val_loss: 0.7802 - val_accuracy: 0.7358\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6969 - accuracy: 0.7338 - val_loss: 0.7711 - val_accuracy: 0.7249\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6828 - accuracy: 0.7462 - val_loss: 0.7646 - val_accuracy: 0.7282\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6844 - accuracy: 0.7473 - val_loss: 0.7729 - val_accuracy: 0.7369\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.6786 - accuracy: 0.7487 - val_loss: 0.7514 - val_accuracy: 0.7314\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.6636 - accuracy: 0.7567 - val_loss: 0.7508 - val_accuracy: 0.7325\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6720 - accuracy: 0.7462 - val_loss: 0.7514 - val_accuracy: 0.7347\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6532 - accuracy: 0.7633 - val_loss: 0.7771 - val_accuracy: 0.7325\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6486 - accuracy: 0.7578 - val_loss: 0.7754 - val_accuracy: 0.7325\n",
      "Epoch 00035: early stopping\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "# https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Course%202%20-%20Part%204%20-%20Lesson%202%20-%20Notebook%20(Cats%20v%20Dogs%20Augmentation).ipynb\n",
    "data_aug_rot2 = Sequential(\n",
    "  [\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(128,128,3)),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.1)\n",
    "  ]\n",
    ")\n",
    "\n",
    "\n",
    "model_aug_rot2 = Sequential()\n",
    "\n",
    "model_aug_rot2.add(data_aug_rot2)\n",
    "\n",
    "model_aug_rot2.add(Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)))\n",
    "model_aug_rot2.add(MaxPooling2D(2, 2))\n",
    "model_aug_rot2.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model_aug_rot2.add(MaxPooling2D(2,2))\n",
    "model_aug_rot2.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model_aug_rot2.add(MaxPooling2D(2,2))\n",
    "model_aug_rot2.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model_aug_rot2.add(MaxPooling2D(2,2))\n",
    "\n",
    "model_aug_rot2.add(Flatten())\n",
    "\n",
    "model_aug_rot2.add(Dense(512, activation='relu'))\n",
    "model_aug_rot2.add(Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "model_aug_rot2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "history_aug_rot2 = model_aug_rot2.fit(X_train, y_train, validation_data = (X_test, y_test),\n",
    "                 batch_size = 256,\n",
    "                 epochs = 100,\n",
    "                 verbose = 1,\n",
    "                  callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.734742720382928"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_aug2 = model_aug_rot2.predict(X_test)\n",
    "quadratic_weighted_kappa(np.argmax(y_test,axis=1), np.argmax(pred_aug2,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was the best model so far with the highest Kappa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion for This Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately from here on out, the scores did not get better. I believe the reason for that is because images that are too augmented cause the model to learn what an augmented retina looks like, and it is unable to bring that learning over to non-augmented images. I've left the following unsuccessful models for those who wanted to see the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 1.3427 - accuracy: 0.4337 - val_loss: 1.2381 - val_accuracy: 0.4924\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 1.2278 - accuracy: 0.4934 - val_loss: 1.1732 - val_accuracy: 0.4924\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 1.1795 - accuracy: 0.4931 - val_loss: 1.1324 - val_accuracy: 0.5098\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 1.1374 - accuracy: 0.5244 - val_loss: 1.0947 - val_accuracy: 0.5764\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 1.0821 - accuracy: 0.5765 - val_loss: 0.9642 - val_accuracy: 0.6605\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.9812 - accuracy: 0.6347 - val_loss: 0.9603 - val_accuracy: 0.6496\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.8999 - accuracy: 0.6679 - val_loss: 0.8602 - val_accuracy: 0.6910\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.8463 - accuracy: 0.6937 - val_loss: 0.8541 - val_accuracy: 0.6965\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.8130 - accuracy: 0.7003 - val_loss: 0.8606 - val_accuracy: 0.6932\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.8008 - accuracy: 0.6985 - val_loss: 0.8349 - val_accuracy: 0.7020\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7767 - accuracy: 0.7210 - val_loss: 0.7942 - val_accuracy: 0.7129\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7717 - accuracy: 0.7210 - val_loss: 0.8306 - val_accuracy: 0.7085\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.7723 - accuracy: 0.7214 - val_loss: 0.8281 - val_accuracy: 0.7052\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7499 - accuracy: 0.7265 - val_loss: 0.8337 - val_accuracy: 0.7172\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7425 - accuracy: 0.7269 - val_loss: 0.7888 - val_accuracy: 0.7172\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7335 - accuracy: 0.7309 - val_loss: 0.8374 - val_accuracy: 0.7118\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.7235 - accuracy: 0.7407 - val_loss: 0.8014 - val_accuracy: 0.7227\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.7178 - accuracy: 0.7338 - val_loss: 0.8211 - val_accuracy: 0.7031\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.7159 - accuracy: 0.7393 - val_loss: 0.7656 - val_accuracy: 0.7183\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.7089 - accuracy: 0.7447 - val_loss: 0.7951 - val_accuracy: 0.7183\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.7062 - accuracy: 0.7484 - val_loss: 0.7568 - val_accuracy: 0.7303\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6992 - accuracy: 0.7436 - val_loss: 0.7702 - val_accuracy: 0.7358\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.6900 - accuracy: 0.7425 - val_loss: 0.8095 - val_accuracy: 0.7172\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6872 - accuracy: 0.7429 - val_loss: 0.7720 - val_accuracy: 0.7358\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.6709 - accuracy: 0.7520 - val_loss: 0.7869 - val_accuracy: 0.7227\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6875 - accuracy: 0.7480 - val_loss: 0.7764 - val_accuracy: 0.7282\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.6902 - accuracy: 0.7462 - val_loss: 0.7801 - val_accuracy: 0.7369\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6768 - accuracy: 0.7422 - val_loss: 0.7599 - val_accuracy: 0.7325\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6739 - accuracy: 0.7487 - val_loss: 0.7630 - val_accuracy: 0.7347\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.6754 - accuracy: 0.7447 - val_loss: 0.7683 - val_accuracy: 0.7402\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.6621 - accuracy: 0.7578 - val_loss: 0.7610 - val_accuracy: 0.7325\n",
      "Epoch 00031: early stopping\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "# https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Course%202%20-%20Part%204%20-%20Lesson%202%20-%20Notebook%20(Cats%20v%20Dogs%20Augmentation).ipynb\n",
    "data_aug_rot5 = Sequential(\n",
    "  [\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(128,128,3)),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.5),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.1)\n",
    "  ]\n",
    ")\n",
    "\n",
    "\n",
    "model_aug_rot5 = Sequential()\n",
    "\n",
    "model_aug_rot5.add(data_aug_rot2)\n",
    "\n",
    "model_aug_rot5.add(Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)))\n",
    "model_aug_rot5.add(MaxPooling2D(2, 2))\n",
    "model_aug_rot5.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model_aug_rot5.add(MaxPooling2D(2,2))\n",
    "model_aug_rot5.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model_aug_rot5.add(MaxPooling2D(2,2))\n",
    "model_aug_rot5.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model_aug_rot5.add(MaxPooling2D(2,2))\n",
    "\n",
    "model_aug_rot5.add(Flatten())\n",
    "\n",
    "model_aug_rot5.add(Dense(512, activation='relu'))\n",
    "model_aug_rot5.add(Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "model_aug_rot5.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "history_aug_rot5 = model_aug_rot5.fit(X_train, y_train, validation_data = (X_test, y_test),\n",
    "                 batch_size = 256,\n",
    "                 epochs = 100,\n",
    "                 verbose = 1,\n",
    "                  callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7269929076392998"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_aug5 = model_aug_rot5.predict(X_test)\n",
    "quadratic_weighted_kappa(np.argmax(y_test,axis=1), np.argmax(pred_aug5,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 1.3432 - accuracy: 0.4297 - val_loss: 1.2722 - val_accuracy: 0.4924\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 1.2284 - accuracy: 0.4931 - val_loss: 1.1694 - val_accuracy: 0.4924\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 1.1792 - accuracy: 0.5018 - val_loss: 1.1104 - val_accuracy: 0.5371\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 1.1277 - accuracy: 0.5408 - val_loss: 1.0502 - val_accuracy: 0.6168\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 1.0681 - accuracy: 0.5834 - val_loss: 0.9458 - val_accuracy: 0.6758\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.9730 - accuracy: 0.6431 - val_loss: 0.8722 - val_accuracy: 0.6954\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.8871 - accuracy: 0.6755 - val_loss: 0.8843 - val_accuracy: 0.6921\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.8583 - accuracy: 0.6799 - val_loss: 0.9340 - val_accuracy: 0.6648\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.8103 - accuracy: 0.6977 - val_loss: 0.9162 - val_accuracy: 0.6845\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.8252 - accuracy: 0.6872 - val_loss: 0.8362 - val_accuracy: 0.6976\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.8082 - accuracy: 0.7039 - val_loss: 0.8156 - val_accuracy: 0.7074\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7845 - accuracy: 0.7167 - val_loss: 0.8471 - val_accuracy: 0.6976\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7733 - accuracy: 0.7130 - val_loss: 0.7928 - val_accuracy: 0.7118\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7423 - accuracy: 0.7320 - val_loss: 0.7972 - val_accuracy: 0.7205\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7431 - accuracy: 0.7327 - val_loss: 0.8181 - val_accuracy: 0.7172\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.7372 - accuracy: 0.7363 - val_loss: 0.8151 - val_accuracy: 0.7074\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7317 - accuracy: 0.7280 - val_loss: 0.7775 - val_accuracy: 0.7238\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.7235 - accuracy: 0.7338 - val_loss: 0.8508 - val_accuracy: 0.7107\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.7212 - accuracy: 0.7360 - val_loss: 0.7969 - val_accuracy: 0.7227\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7244 - accuracy: 0.7345 - val_loss: 0.8123 - val_accuracy: 0.7063\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.7098 - accuracy: 0.7396 - val_loss: 0.7649 - val_accuracy: 0.7271\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7028 - accuracy: 0.7487 - val_loss: 0.7797 - val_accuracy: 0.7325\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.7064 - accuracy: 0.7382 - val_loss: 0.8103 - val_accuracy: 0.7205\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.7026 - accuracy: 0.7425 - val_loss: 0.7832 - val_accuracy: 0.7325\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.6925 - accuracy: 0.7509 - val_loss: 0.7483 - val_accuracy: 0.7216\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6883 - accuracy: 0.7458 - val_loss: 0.7672 - val_accuracy: 0.7303\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.6873 - accuracy: 0.7389 - val_loss: 0.8065 - val_accuracy: 0.7293\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.7155 - accuracy: 0.7287 - val_loss: 0.7798 - val_accuracy: 0.7358\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.6908 - accuracy: 0.7498 - val_loss: 0.7938 - val_accuracy: 0.7325\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6965 - accuracy: 0.7454 - val_loss: 0.7540 - val_accuracy: 0.7303\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.6736 - accuracy: 0.7509 - val_loss: 0.7693 - val_accuracy: 0.7402\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.6688 - accuracy: 0.7524 - val_loss: 0.7544 - val_accuracy: 0.7391\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.6701 - accuracy: 0.7505 - val_loss: 0.7752 - val_accuracy: 0.7358\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 26s 2s/step - loss: 0.6623 - accuracy: 0.7542 - val_loss: 0.7675 - val_accuracy: 0.7271\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.6548 - accuracy: 0.7600 - val_loss: 0.7731 - val_accuracy: 0.7369\n",
      "Epoch 00035: early stopping\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "# https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Course%202%20-%20Part%204%20-%20Lesson%202%20-%20Notebook%20(Cats%20v%20Dogs%20Augmentation).ipynb\n",
    "data_rot2_zoom2 = Sequential(\n",
    "  [\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(128,128,3)),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.2)\n",
    "  ]\n",
    ")\n",
    "\n",
    "\n",
    "model_rot2_zoom2 = Sequential()\n",
    "\n",
    "model_rot2_zoom2.add(data_aug_rot2)\n",
    "\n",
    "model_rot2_zoom2.add(Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)))\n",
    "model_rot2_zoom2.add(MaxPooling2D(2, 2))\n",
    "model_rot2_zoom2.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model_rot2_zoom2.add(MaxPooling2D(2,2))\n",
    "model_rot2_zoom2.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model_rot2_zoom2.add(MaxPooling2D(2,2))\n",
    "model_rot2_zoom2.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model_rot2_zoom2.add(MaxPooling2D(2,2))\n",
    "\n",
    "model_rot2_zoom2.add(Flatten())\n",
    "\n",
    "model_rot2_zoom2.add(Dense(512, activation='relu'))\n",
    "model_rot2_zoom2.add(Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "model_rot2_zoom2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "history_rot2_zoom2 = model_rot2_zoom2.fit(X_train, y_train, validation_data = (X_test, y_test),\n",
    "                 batch_size = 256,\n",
    "                 epochs = 100,\n",
    "                 verbose = 1,\n",
    "                  callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.698853915926805"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_rot2_zoom2 = model_rot2_zoom2.predict(X_test)\n",
    "quadratic_weighted_kappa(np.argmax(y_test,axis=1), np.argmax(pred_rot2_zoom2,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 28s 2s/step - loss: 1.3332 - accuracy: 0.4410 - val_loss: 1.2107 - val_accuracy: 0.4924\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 1.2129 - accuracy: 0.4931 - val_loss: 1.1499 - val_accuracy: 0.4924\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 1.1643 - accuracy: 0.5058 - val_loss: 1.0823 - val_accuracy: 0.5360\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 1.0822 - accuracy: 0.5845 - val_loss: 0.9748 - val_accuracy: 0.6539\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.9917 - accuracy: 0.6289 - val_loss: 0.8937 - val_accuracy: 0.6834\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.9180 - accuracy: 0.6664 - val_loss: 0.9057 - val_accuracy: 0.6725\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.8641 - accuracy: 0.6766 - val_loss: 0.9012 - val_accuracy: 0.6878\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.8308 - accuracy: 0.6963 - val_loss: 0.8237 - val_accuracy: 0.6987\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7946 - accuracy: 0.7054 - val_loss: 0.8535 - val_accuracy: 0.6965\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.7972 - accuracy: 0.7010 - val_loss: 0.8551 - val_accuracy: 0.6954\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.7813 - accuracy: 0.7109 - val_loss: 0.8000 - val_accuracy: 0.7183\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7584 - accuracy: 0.7243 - val_loss: 0.8043 - val_accuracy: 0.7129\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.7743 - accuracy: 0.7207 - val_loss: 0.8179 - val_accuracy: 0.7041\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7441 - accuracy: 0.7258 - val_loss: 0.8208 - val_accuracy: 0.7172\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7389 - accuracy: 0.7254 - val_loss: 0.7928 - val_accuracy: 0.7162\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 27s 2s/step - loss: 0.7292 - accuracy: 0.7280 - val_loss: 0.7996 - val_accuracy: 0.7151\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7194 - accuracy: 0.7331 - val_loss: 0.7844 - val_accuracy: 0.7282\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7205 - accuracy: 0.7302 - val_loss: 0.8018 - val_accuracy: 0.7172\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7150 - accuracy: 0.7356 - val_loss: 0.7662 - val_accuracy: 0.7227\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7227 - accuracy: 0.7407 - val_loss: 0.7761 - val_accuracy: 0.7162\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7147 - accuracy: 0.7356 - val_loss: 0.8297 - val_accuracy: 0.7260\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7087 - accuracy: 0.7382 - val_loss: 0.7653 - val_accuracy: 0.7293\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7045 - accuracy: 0.7367 - val_loss: 0.7436 - val_accuracy: 0.7336\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6865 - accuracy: 0.7520 - val_loss: 0.7668 - val_accuracy: 0.7260\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6865 - accuracy: 0.7516 - val_loss: 0.7799 - val_accuracy: 0.7249\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6859 - accuracy: 0.7465 - val_loss: 0.7760 - val_accuracy: 0.7172\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6735 - accuracy: 0.7480 - val_loss: 0.8311 - val_accuracy: 0.7162\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.7024 - accuracy: 0.7367 - val_loss: 0.7672 - val_accuracy: 0.7347\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 27s 3s/step - loss: 0.6934 - accuracy: 0.7469 - val_loss: 0.7606 - val_accuracy: 0.7303\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6814 - accuracy: 0.7454 - val_loss: 0.7724 - val_accuracy: 0.7347\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.6692 - accuracy: 0.7509 - val_loss: 0.7742 - val_accuracy: 0.7358\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 29s 3s/step - loss: 0.6618 - accuracy: 0.7498 - val_loss: 0.8097 - val_accuracy: 0.7118\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 28s 3s/step - loss: 0.6694 - accuracy: 0.7491 - val_loss: 0.7762 - val_accuracy: 0.7336\n",
      "Epoch 00033: early stopping\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "# https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Course%202%20-%20Part%204%20-%20Lesson%202%20-%20Notebook%20(Cats%20v%20Dogs%20Augmentation).ipynb\n",
    "data_rot2_only = Sequential(\n",
    "  [\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(128,128,3)),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.2)\n",
    "  ]\n",
    ")\n",
    "\n",
    "\n",
    "model_rot2_only = Sequential()\n",
    "\n",
    "model_rot2_only.add(data_aug_rot2)\n",
    "\n",
    "model_rot2_only.add(Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)))\n",
    "model_rot2_only.add(MaxPooling2D(2, 2))\n",
    "model_rot2_only.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model_rot2_only.add(MaxPooling2D(2,2))\n",
    "model_rot2_only.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model_rot2_only.add(MaxPooling2D(2,2))\n",
    "model_rot2_only.add(Conv2D(128, (3,3), activation='relu'))\n",
    "model_rot2_only.add(MaxPooling2D(2,2))\n",
    "\n",
    "model_rot2_only.add(Flatten())\n",
    "\n",
    "model_rot2_only.add(Dense(512, activation='relu'))\n",
    "model_rot2_only.add(Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "model_rot2_only.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "history_rot2_only = model_rot2_only.fit(X_train, y_train, validation_data = (X_test, y_test),\n",
    "                 batch_size = 256,\n",
    "                 epochs = 100,\n",
    "                 verbose = 1,\n",
    "                  callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7191814746392702"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_rot2_only = model_rot2_only.predict(X_test)\n",
    "quadratic_weighted_kappa(np.argmax(y_test,axis=1), np.argmax(pred_rot2_only,axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
